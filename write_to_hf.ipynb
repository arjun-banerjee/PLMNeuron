{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39eacc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afe9275",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ubuntu/protolyze/datageneration/esm8M_500kdataset_k30_optimized.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     records \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)           \u001b[38;5;66;03m# assume a list of dicts\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ds_json \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m ds_json\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotolyzee/esm8M_500kdataset_k30_optimized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/datasets/arrow_dataset.py:985\u001b[0m, in \u001b[0;36mDataset.from_list\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;03mConvert a list of dicts to a `pyarrow.Table` to create a [`Dataset`]`.\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m    [`Dataset`]\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here\u001b[39;00m\n\u001b[0;32m--> 985\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {k: [r\u001b[38;5;241m.\u001b[39mget(k) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m mapping] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m} \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(mapping, features, info, split)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# JSON â†’ HF Dataset\n",
    "with open(\"/home/ubuntu/protolyze/datageneration/esm8M_500kdataset_k30_optimized.json\") as f:\n",
    "    records = json.load(f)           # assume a list of dicts\n",
    "ds_json = Dataset.from_list(records)\n",
    "ds_json.push_to_hub(\"protolyzee/esm8M_500kdataset_k30_optimized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb91f72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba11968c60a494e8dc8527493a8fd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76bd7eb3cee4ee7a65c4e76afe24704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e47622ba7341d08bfa8e64a723e27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/81.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/protolyze/esm35M_500kdataset_k30_optimized/commit/debd947871c6f41e5731d850d4117eda165c8200', commit_message='Upload dataset', commit_description='', oid='debd947871c6f41e5731d850d4117eda165c8200', pr_url='https://huggingface.co/datasets/protolyze/esm35M_500kdataset_k30_optimized/discussions/1', repo_url=RepoUrl('https://huggingface.co/datasets/protolyze/esm35M_500kdataset_k30_optimized', endpoint='https://huggingface.co', repo_type='dataset', repo_id='protolyze/esm35M_500kdataset_k30_optimized'), pr_revision='refs/pr/1', pr_num=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "with open(\"/home/ubuntu/protolyze/datageneration/esm35M_500kdataset_k30_optimized.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# If `data` is a dict mapping IDsâ†’records, convert to list:\n",
    "if isinstance(data, dict):\n",
    "    records = list(data.values())\n",
    "elif isinstance(data, list):\n",
    "    records = data\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected JSON topâ€level type: {type(data)}\")\n",
    "\n",
    "# Now this should work:\n",
    "ds_json = Dataset.from_list(records)\n",
    "ds_json.push_to_hub(\"protolyze/esm35M_500kdataset_k30_optimized\", create_pr=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99295ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV â†’ HF Dataset\n",
    "ds_csv = Dataset.from_csv(\"my_table.csv\")  # auto-parses header row\n",
    "ds_csv.push_to_hub(\"your-username/my-csv-dataset\", create_pr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5434e751",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://huggingface.co/api/repos/create",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/repos/create",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3) Create the dataset repo (no error if it already exists)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 4) Load it as a HF Dataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# if JSON-lines use lines=True\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3746\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3743\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3746\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m   3749\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/repos/create"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import HfApi\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1) Log in with `huggingface-cli login` beforehand or set HF_TOKEN env var.\n",
    "api = HfApi()\n",
    "user = \"protolyze\"\n",
    "\n",
    "# 2) Loop over your files\n",
    "for path in Path(\"/home/ubuntu/protolyze/analysis/\").glob(\"*\"):\n",
    "    time.sleep(2)\n",
    "    name = path.stem                # e.g. \"my_records\" or \"table\"\n",
    "    repo_id = f\"{user}/{name}\"\n",
    "\n",
    "    # 3) Create the dataset repo (no error if it already exists)\n",
    "    api.create_repo(repo_id=repo_id, repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "    # 4) Load it as a HF Dataset\n",
    "    if path.suffix == \".json\":\n",
    "        # if JSON-lines use lines=True\n",
    "        ds = load_dataset(\"json\", data_files=str(path), split=\"train\", lines=False)\n",
    "    elif path.suffix == \".csv\":\n",
    "        ds = load_dataset(\"csv\", data_files=str(path), split=\"train\")\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # 5) Push to Hub\n",
    "   \n",
    "    ds.push_to_hub(repo_id)\n",
    "    \n",
    "    print(f\"Pushed {path.name} â†’ {repo_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c0a8a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HfApi' object has no attribute 'list_repos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotolyze\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 2) Fetch all of your existing dataset repo names\u001b[39;00m\n\u001b[1;32m     10\u001b[0m existing \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     repo\u001b[38;5;241m.\u001b[39mrepo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m repo \u001b[38;5;129;01min\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_repos\u001b[49m(token\u001b[38;5;241m=\u001b[39mapi\u001b[38;5;241m.\u001b[39mtoken, repo_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3) Loop over your local files\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ubuntu/protolyze/analysis/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HfApi' object has no attribute 'list_repos'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import HfApi\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1) Log in with `huggingface-cli login` beforehand or set HF_TOKEN env var.\n",
    "api = HfApi()\n",
    "user = \"protolyze\"\n",
    "\n",
    "# 2) Fetch all of your existing dataset repo names\n",
    "existing = {\n",
    "    repo.repo_id.split(\"/\")[-1]\n",
    "    for repo in api.list_repos(token=api.token, repo_type=\"dataset\")\n",
    "}\n",
    "\n",
    "# 3) Loop over your local files\n",
    "for path in Path(\"/home/ubuntu/protolyze/analysis/\").glob(\"*\"):\n",
    "    name = path.stem               # e.g. \"esm8M_500kdataset_k30_optimized\"\n",
    "    repo_id = f\"{user}/{name}\"\n",
    "\n",
    "    # 4) Create the repo only if it doesn't already exist\n",
    "    if name not in existing:\n",
    "        api.create_repo(repo_id=repo_id, repo_type=\"dataset\", exist_ok=True)\n",
    "        print(f\"Created new dataset repo: {repo_id}\")\n",
    "    else:\n",
    "        print(f\"Dataset repo already exists: {repo_id} (will overwrite)\")\n",
    "\n",
    "    # 5) Load local file into a HF Dataset object\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix == \".jsonl\":\n",
    "        ds = load_dataset(\"json\", data_files=str(path), split=\"train\", lines=True)\n",
    "    elif suffix == \".json\":\n",
    "        ds = load_dataset(\"json\", data_files=str(path), split=\"train\", lines=False)\n",
    "    elif suffix == \".csv\":\n",
    "        ds = load_dataset(\"csv\",  data_files=str(path), split=\"train\")\n",
    "    else:\n",
    "        print(f\"Skipping unsupported file type: {path.name}\")\n",
    "        continue\n",
    "\n",
    "    # 6) Push to Hub (this will overwrite existing content in the repo)\n",
    "    ds.push_to_hub(repo_id, use_auth_token=True)\n",
    "    print(f\"Pushed {path.name} â†’ {repo_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33addb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Repo already exists: protolyze/simulator_finetune (overwriting)\n",
      "âš ï¸ Skipping unsupported file: simulator_finetune\n",
      "ðŸ”„ Repo already exists: protolyze/steering_experiment_1 (overwriting)\n",
      "âš ï¸ Skipping unsupported file: steering_experiment_1.png\n",
      "ðŸ”„ Repo already exists: protolyze/__pycache__ (overwriting)\n",
      "âš ï¸ Skipping unsupported file: __pycache__\n",
      "ðŸ”„ Repo already exists: protolyze/gravy_masked_steering (overwriting)\n",
      "âš ï¸ Skipping unsupported file: gravy_masked_steering.png\n",
      "ðŸ”„ Repo already exists: protolyze/combined_steering_experiments_custom_titles (overwriting)\n",
      "âš ï¸ Skipping unsupported file: combined_steering_experiments_custom_titles.png\n",
      "ðŸ”„ Repo already exists: protolyze/simulator (overwriting)\n",
      "âš ï¸ Skipping unsupported file: simulator.py\n",
      "ðŸ”„ Repo already exists: protolyze/semantic_search (overwriting)\n",
      "âš ï¸ Skipping unsupported file: semantic_search.py\n",
      "ðŸ”„ Repo already exists: protolyze/line_plots_by_label_combo (overwriting)\n",
      "âš ï¸ Skipping unsupported file: line_plots_by_label_combo.png\n",
      "ðŸ”„ Repo already exists: protolyze/steered_sequences_dual (overwriting)\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://huggingface.co/api/repos/create",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/repos/create",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# 6) Push (will overwrite existing data)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43msafe_push\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 35\u001b[0m, in \u001b[0;36msafe_push\u001b[0;34m(ds, repo_id, max_retries)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ Pushed data â†’ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/datasets/arrow_dataset.py:5544\u001b[0m, in \u001b[0;36mDataset.push_to_hub\u001b[0;34m(self, repo_id, config_name, set_default, split, data_dir, commit_message, commit_description, private, token, revision, create_pr, max_shard_size, num_shards, embed_external_files)\u001b[0m\n\u001b[1;32m   5540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplit name should match \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_split_re\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5542\u001b[0m api \u001b[38;5;241m=\u001b[39m HfApi(endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT, token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[0;32m-> 5544\u001b[0m repo_url \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   5550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5551\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m repo_url\u001b[38;5;241m.\u001b[39mrepo_id\n\u001b[1;32m   5553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m revision\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefs/pr/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   5554\u001b[0m     \u001b[38;5;66;03m# We do not call create_branch for a PR reference: 400 Bad Request\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3746\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3743\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3746\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m   3749\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm_env/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:482\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/repos/create"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "from huggingface_hub import HfApi\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1) Log in with `huggingface-cli login` beforehand or set HF_TOKEN env var.\n",
    "api  = HfApi()\n",
    "user = \"protolyze\"\n",
    "\n",
    "# 2) Fetch your existing dataset repo names\n",
    "existing = {\n",
    "    ds.id.split(\"/\")[-1]\n",
    "    for ds in api.list_datasets(author=user, token=api.token)\n",
    "}\n",
    "\n",
    "def safe_create_repo(repo_id, max_retries=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            api.create_repo(repo_id=repo_id, repo_type=\"dataset\", exist_ok=True)\n",
    "            print(f\"âœ… Created dataset repo: {repo_id}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            # If it's an HTTP 429, retry with backoff\n",
    "            status = getattr(e, \"status_code\", None)\n",
    "            if status == 429 and attempt < max_retries - 1:\n",
    "                wait = 2 ** attempt\n",
    "                print(f\"â³ Rate limited creating {repo_id}, retrying in {wait}sâ€¦\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "def safe_push(ds, repo_id, max_retries=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            ds.push_to_hub(repo_id)\n",
    "            print(f\"ðŸš€ Pushed data â†’ {repo_id}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            status = getattr(e, \"status_code\", None)\n",
    "            if status == 429 and attempt < max_retries - 1:\n",
    "                wait = 2 ** attempt\n",
    "                print(f\"â³ Rate limited pushing {repo_id}, retrying in {wait}sâ€¦\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "# 3) Loop over your local files\n",
    "for path in Path(\"/home/ubuntu/protolyze/analysis/\").glob(\"*\"):\n",
    "    name    = path.stem\n",
    "    repo_id = f\"{user}/{name}\"\n",
    "\n",
    "    # 4) Create the repo only if missing\n",
    "    if name not in existing:\n",
    "        safe_create_repo(repo_id)\n",
    "        existing.add(name)\n",
    "    else:\n",
    "        print(f\"ðŸ”„ Repo already exists: {repo_id} (overwriting)\")\n",
    "\n",
    "    # 5) Load the file as a Dataset\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".jsonl\":\n",
    "        ds = load_dataset(\"json\", data_files=str(path), split=\"train\", lines=True)\n",
    "    elif ext == \".json\":\n",
    "        ds = load_dataset(\"json\", data_files=str(path), split=\"train\", lines=False)\n",
    "    elif ext == \".csv\":\n",
    "        ds = load_dataset(\"csv\",  data_files=str(path), split=\"train\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Skipping unsupported file: {path.name}\")\n",
    "        continue\n",
    "\n",
    "    # 6) Push (will overwrite existing data)\n",
    "    safe_push(ds, repo_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e16972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
