{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from tqdm import tqdm\n",
    "from modlamp.descriptors import GlobalDescriptor\n",
    "import pyarrow as pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tqdm.auto import tqdm\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def fetch_uniprot_cursor(query: str = \"reviewed:true\", total: int = 1000, batch_size=500) -> pd.DataFrame:\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    fields = (\n",
    "        \"accession,id,protein_name,organism_name,length,sequence,mass,\"\n",
    "        \"cc_subcellular_location,go_p,go_f,ec,cc_disruption_phenotype,\"\n",
    "        \"cc_catalytic_activity,cc_pathway,cc_subcellular_location,\"\n",
    "        \"cc_function,cc_domain,cc_induction,cc_pharmaceutical,\"\n",
    "        \"cc_disruption_phenotype\"\n",
    "    )\n",
    "\n",
    "    headers = {\"Accept\": \"text/tab-separated-values\"}\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"tsv\",\n",
    "        \"fields\": fields,\n",
    "        \"size\": batch_size,\n",
    "    }\n",
    "\n",
    "    # Set up retry strategy\n",
    "    retry_strategy = Retry(\n",
    "        total=30,\n",
    "        backoff_factor=2,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session = requests.Session()\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.mount(\"http://\", adapter)\n",
    "\n",
    "    results = []\n",
    "    next_url = base_url\n",
    "    fetched = 0\n",
    "\n",
    "    with tqdm(total=total, desc=\"Fetching UniProt entries\") as pbar:\n",
    "        while next_url and fetched < total:\n",
    "            try:\n",
    "                if fetched == 0:\n",
    "                    resp = session.get(next_url, params=params, headers=headers, timeout=10)\n",
    "                else:\n",
    "                    resp = session.get(next_url, headers=headers, timeout=10)\n",
    "                resp.raise_for_status()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                break\n",
    "\n",
    "            df = pd.read_csv(StringIO(resp.text), sep=\"\\t\")\n",
    "            if df.empty:\n",
    "                break\n",
    "\n",
    "            results.append(df)\n",
    "            fetched += len(df)\n",
    "            pbar.update(len(df))\n",
    "\n",
    "            # get next URL from headers (cursor-based)\n",
    "            next_url = resp.links.get(\"next\", {}).get(\"url\", None)\n",
    "\n",
    "    if results:\n",
    "        return pd.concat(results, ignore_index=True).iloc[:total].reset_index(drop=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def fetch_uniprot_batches_parallel(\n",
    "    query: str = \"reviewed:true\",\n",
    "    batch_size: int = 500,\n",
    "    total: int = 1000,\n",
    "    max_workers: int = 32 \n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parallelized fetch of UniProt search results in TSV format.\n",
    "\n",
    "    Args:\n",
    "      query: UniProt query string\n",
    "      batch_size: number of entries per page\n",
    "      total: total entries desired\n",
    "      max_workers: number of threads to use for HTTP fetches\n",
    "\n",
    "    Returns:\n",
    "      Pandas DataFrame with up to `total` rows.\n",
    "    \"\"\"\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    fields = (\n",
    "        \"accession,id,protein_name,organism_name,length,sequence,mass,\"\n",
    "        \"cc_subcellular_location,go_p,go_f,ec,cc_disruption_phenotype,\"\n",
    "        \"cc_catalytic_activity,cc_pathway,cc_subcellular_location,\"\n",
    "        \"cc_function,cc_domain,cc_induction,cc_pharmaceutical,\"\n",
    "        \"cc_disruption_phenotype\"\n",
    "    )\n",
    "\n",
    "    # how many pages we need\n",
    "    num_pages = math.ceil(total / batch_size)\n",
    "    \n",
    "    def fetch_page(offset: int) -> pd.DataFrame:\n",
    "        params = {\n",
    "            \"query\": query,\n",
    "            \"format\": \"tsv\",\n",
    "            \"fields\": fields,\n",
    "            \"size\": batch_size,\n",
    "            \"offset\": offset\n",
    "        }\n",
    "        resp = requests.get(base_url, params=params)\n",
    "        resp.raise_for_status()\n",
    "        return pd.read_csv(StringIO(resp.text), sep=\"\\t\")\n",
    "\n",
    "    # kick off all page fetches\n",
    "    offsets = [i * batch_size for i in range(num_pages)]\n",
    "    dfs = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(fetch_page, off): off for off in offsets}\n",
    "        for future in tqdm(as_completed(futures),\n",
    "                           total=len(futures),\n",
    "                           desc=\"UniProt pages\"):\n",
    "            df = future.result()\n",
    "            if df.empty:\n",
    "                break\n",
    "            dfs.append(df)\n",
    "\n",
    "    # combine and cap to `total`\n",
    "    all_data = pd.concat(dfs, ignore_index=True)\n",
    "    return all_data.iloc[:total].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_uniprot_batches(query=\"reviewed:true\", batch_size=500, total=10000):\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    all_dataframes = []\n",
    "    fetched = 0\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"tsv\",\n",
    "        \"fields\": (\n",
    "            \"accession,id,protein_name,organism_name,length,sequence,mass,\"\n",
    "            \"cc_subcellular_location,go_p,go_f,ec,cc_disruption_phenotype,\"\n",
    "            \"cc_catalytic_activity,cc_pathway,cc_function,cc_domain,\"\n",
    "            \"cc_induction,cc_pharmaceutical\"\n",
    "        ),\n",
    "        \"size\": batch_size,\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if not response.ok:\n",
    "        raise Exception(f\"Initial fetch failed: {response.status_code} {response.text}\")\n",
    "\n",
    "    with tqdm(total=total, desc=\"Fetching UniProt entries\") as pbar:\n",
    "        while True:\n",
    "            df_batch = pd.read_csv(StringIO(response.text), sep=\"\\t\")\n",
    "            if df_batch.empty:\n",
    "                break\n",
    "\n",
    "            all_dataframes.append(df_batch)\n",
    "            batch_size = len(df_batch)\n",
    "            fetched += batch_size\n",
    "            pbar.update(batch_size)\n",
    "\n",
    "            if fetched >= total:\n",
    "                break\n",
    "\n",
    "          # Get full next URL from response.links\n",
    "            next_url = response.links.get(\"next\", {}).get(\"url\", None)\n",
    "            if not next_url:\n",
    "                break\n",
    "\n",
    "            response = requests.get(next_url)\n",
    "            if not response.ok:\n",
    "                raise Exception(f\"Next fetch failed: {response.status_code} {response.text}\")\n",
    "\n",
    "    return pd.concat(all_dataframes, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biopython_features(seq: str, entry: str) -> dict:\n",
    "    analysis = ProteinAnalysis(seq)\n",
    "\n",
    "    try:\n",
    "        aa_counts = analysis.count_amino_acids()\n",
    "        aa_percents = analysis.get_amino_acids_percent()\n",
    "        sec_frac = analysis.secondary_structure_fraction()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on sequence: {seq} - {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        features = {\n",
    "            \"Entry\": entry,\n",
    "            \"Sequence\": seq,\n",
    "            \"length\": len(seq),\n",
    "            \"mol_weight\": analysis.molecular_weight(),\n",
    "            \"iso_point\": analysis.isoelectric_point(),\n",
    "            \"aromaticity\": analysis.aromaticity(),\n",
    "            \"instability_index\": analysis.instability_index(),\n",
    "            \"gravy\": analysis.gravy(),\n",
    "            \"helix_frac\": sec_frac[0],\n",
    "            \"turn_frac\": sec_frac[1],\n",
    "            \"sheet_frac\": sec_frac[2],\n",
    "        }\n",
    "    except Exception as e:\n",
    "        #print(f\"Failed to compute features for sequence: {seq} - {e}\")\n",
    "        return None\n",
    "\n",
    "    # Add amino acid counts and percents\n",
    "    for aa in aa_counts:\n",
    "        features[f\"count_{aa}\"] = aa_counts[aa]\n",
    "        features[f\"percent_{aa}\"] = round(aa_percents[aa],3)\n",
    "\n",
    "    \n",
    "    # --- modlamp GlobalDescriptor ---\n",
    "    try:\n",
    "        desc = GlobalDescriptor([seq])\n",
    "        desc.calculate_all()\n",
    "        modlamp_feats = desc.descriptor[0]\n",
    "        modlamp_names = [\n",
    "            \"charge_pH7\", \"boman_index\", \"aliphatic_index\", \"hydrophobic_moment\"\n",
    "        ]\n",
    "\n",
    "        for name, value in zip(modlamp_names, modlamp_feats):\n",
    "            orig_name = name.split(\"_\", 1)[-1]\n",
    "            features[name] = value\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(f\"modlamp failed on sequence: {seq} - {e}\")\n",
    "        return None\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def parallel_compute_features(seq_entry_list, max_workers=None):\n",
    "    \"\"\"\n",
    "    seq_entry_list: List of (seq, entry) tuples\n",
    "    max_workers:    Number of processes to spin up (defaults to os.cpu_count())\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # schedule all the jobs\n",
    "        futures = {\n",
    "            executor.submit(compute_biopython_features, seq, entry): (seq, entry)\n",
    "            for seq, entry in seq_entry_list\n",
    "        }\n",
    "\n",
    "        # progress over completions\n",
    "        for future in tqdm(as_completed(futures),\n",
    "                           total=len(futures),\n",
    "                           desc=\"Computing features\"):\n",
    "            seq, entry = futures[future]\n",
    "            try:\n",
    "                feat = future.result()\n",
    "                if feat is not None:\n",
    "                    results.append(feat)\n",
    "            except Exception as exc:\n",
    "                print(f\"[Worker error] seq={entry} raised {exc!r}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching UniProt entries:  57%|█████▋    | 573230/1000000 [31:27<23:25, 303.64it/s]  \n"
     ]
    }
   ],
   "source": [
    "df = fetch_uniprot_cursor(batch_size=500, total= 1000000)\n",
    "df_filtered = df[df['Length'] <= 1024]\n",
    "df_filtered = df = df.drop(columns=['Pharmaceutical use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entry                                 573230\n",
       "Entry Name                            573230\n",
       "Protein names                         169016\n",
       "Organism                               14778\n",
       "Length                                  3476\n",
       "Sequence                              484998\n",
       "Mass                                  110205\n",
       "Subcellular location [CC]              59530\n",
       "Gene Ontology (biological process)     66513\n",
       "Gene Ontology (molecular function)     40407\n",
       "EC number                               7141\n",
       "Disruption phenotype                   19948\n",
       "Catalytic activity                     30481\n",
       "Pathway                                 8622\n",
       "Subcellular location [CC].1            59530\n",
       "Function [CC]                         115427\n",
       "Domain [CC]                            13940\n",
       "Induction                              16973\n",
       "Disruption phenotype.1                 19948\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/Bio/SeqUtils/ProtParam.py:106: BiopythonDeprecationWarning: The get_amino_acids_percent method has been deprecated and will likely be removed from Biopython in the near future. Please use the amino_acids_percent attribute instead.\n",
      "  warnings.warn(\n",
      "Computing features: 100%|██████████| 573230/573230 [03:36<00:00, 2653.24it/s]\n"
     ]
    }
   ],
   "source": [
    "sequences = df_filtered[\"Sequence\"].tolist()\n",
    "entry = df_filtered[\"Entry\"].tolist()\n",
    "seq_entry_list = list(zip(sequences, entry))\n",
    "\n",
    "feature_dicts = []\n",
    "feature_dicts = parallel_compute_features(seq_entry_list, max_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570558"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 27/115 [00:19<01:04,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10801\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 28/115 [00:20<01:05,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12678\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 29/115 [00:21<01:05,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12708\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 30/115 [00:22<01:05,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11238\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 31/115 [00:22<01:05,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10276\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 35/115 [00:25<01:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10448\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n",
      "16767\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 37/115 [00:27<01:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10131\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 39/115 [00:29<01:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10169\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 43/115 [00:32<00:56,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12269\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 44/115 [00:33<00:57,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16040\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 46/115 [00:34<00:55,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11678\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 51/115 [00:38<00:50,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13039\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 52/115 [00:39<00:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14423\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 53/115 [00:40<00:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10535\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 54/115 [00:40<00:48,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10205\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 58/115 [00:44<00:43,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10474\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 59/115 [00:44<00:44,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14541\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 60/115 [00:45<00:43,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12714\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 62/115 [00:47<00:41,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10545\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 69/115 [00:52<00:35,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15378\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 70/115 [00:53<00:35,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20265\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 71/115 [00:54<00:35,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18030\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 72/115 [00:54<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14968\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 73/115 [00:55<00:34,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14898\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 74/115 [00:56<00:33,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12249\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 75/115 [00:57<00:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10770\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 76/115 [00:58<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10769\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 77/115 [00:58<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13706\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n",
      "23123\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 79/115 [01:00<00:29,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14540\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 80/115 [01:01<00:28,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14906\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 81/115 [01:02<00:27,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14120\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 82/115 [01:03<00:26,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12117\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 84/115 [01:04<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10592\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 85/115 [01:05<00:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14087\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n",
      "25687\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 87/115 [01:07<00:23,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14366\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 88/115 [01:07<00:22,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13394\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 89/115 [01:08<00:21,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15272\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 90/115 [01:09<00:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11869\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 91/115 [01:10<00:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 92/115 [01:11<00:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10780\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 93/115 [01:11<00:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15211\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n",
      "24402\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 95/115 [01:13<00:16,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12996\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 96/115 [01:14<00:15,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13162\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 97/115 [01:15<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15180\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 98/115 [01:16<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11775\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 100/115 [01:17<00:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11007\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 101/115 [01:18<00:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17336\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n",
      "23378\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 103/115 [01:20<00:09,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13667\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 104/115 [01:20<00:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13929\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 105/115 [01:21<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13960\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 106/115 [01:22<00:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12753\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 109/115 [01:24<00:04,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11336\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 110/115 [01:25<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13064\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 111/115 [01:26<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13697\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 112/115 [01:27<00:02,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11347\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 113/115 [01:27<00:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12132\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 114/115 [01:28<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13494\n",
      "5000\n",
      "Merge resulted in too many rows. Check for duplicates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [01:29<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_path = \"datatest573230.parquet\"\n",
    "chunk_size = 5000\n",
    "writer = None\n",
    "schema = None\n",
    "reference_columns_and_types = None\n",
    "\n",
    "def fix_null_columns(df, reference_columns_and_types):\n",
    "    for col, dtype in reference_columns_and_types.items():\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "        try:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except Exception:\n",
    "            df[col] = df[col].astype(\"object\")\n",
    "    return df\n",
    "\n",
    "def sanitize_for_arrow(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].astype(str)  # Coerce to string\n",
    "    return df\n",
    "\n",
    "for i in tqdm(range(0, len(feature_dicts), chunk_size)):\n",
    "    chunk_df = pd.DataFrame(feature_dicts[i:i + chunk_size])\n",
    "\n",
    "    if reference_columns_and_types is None:\n",
    "        reference_columns_and_types = {\n",
    "            col: str(chunk_df[col].dtype) for col in chunk_df.columns\n",
    "        }\n",
    "\n",
    "    chunk_df = fix_null_columns(chunk_df, reference_columns_and_types)\n",
    "    merged = chunk_df.merge(df, on=\"Sequence\", how=\"left\")\n",
    "\n",
    "    if len(merged) > 2 * len(chunk_df):\n",
    "        print(len(merged))\n",
    "        print(len(chunk_df))\n",
    "        print(\"Merge resulted in too many rows. Check for duplicates.\")\n",
    "\n",
    "    merged = sanitize_for_arrow(merged)\n",
    "\n",
    "    table = pa.Table.from_pandas(merged, preserve_index=False)\n",
    "\n",
    "    if writer is None:\n",
    "        schema = pa.schema([\n",
    "            pa.field(name, typ).with_nullable(True)\n",
    "            for name, typ in zip(table.schema.names, table.schema.types)\n",
    "        ])\n",
    "        writer = pq.ParquetWriter(output_path, schema, compression=\"snappy\")\n",
    "\n",
    "    table = pa.Table.from_pandas(merged, schema=schema, preserve_index=False)\n",
    "    writer.write_table(table)\n",
    "\n",
    "if writer is not None:\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_parquet(\"datatest573230.parquet\", engine=\"pyarrow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entry_x                        570558\n",
       "Sequence                       482356\n",
       "length                           3464\n",
       "mol_weight                     480443\n",
       "iso_point                      101191\n",
       "                                ...  \n",
       "Subcellular location [CC].1     59332\n",
       "Function [CC]                  114896\n",
       "Domain [CC]                     13902\n",
       "Induction                       16931\n",
       "Disruption phenotype.1          19927\n",
       "Length: 73, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdropped = check.drop_duplicates(subset=['Sequence']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482356"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(checkdropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
